{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ1W8pT-M2V2",
        "outputId": "394ed748-04a9-4b13-86a0-0c1d5109f47b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCOCO paths ready: True True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ 2025-9-2 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:00<00:00, 156MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.52s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=11.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.79s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.481\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
            "\n",
            "=== SUMMARY ===\n",
            "mAP@0.5:0.95: 0.321395054998888\n",
            "mAP@0.5    : 0.4805963802894627\n",
            "Precision  : 0.6976470203226528\n",
            "Recall     : 0.5795927245044838\n",
            "Latency(ms): 9.652279317378998 | FPS: 103.60247223673821\n",
            "Params     : 7225885 | Weights file size(bytes): 28954177\n",
            "Train time : 0.0 sec\n",
            "Logs saved : /content/yolov5s_eval_out\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# COCO(val2017) Ã— YOLOv5s í‰ê°€ íŒŒì´í”„ë¼ì¸\n",
        "# - mAP@0.5, mAP@0.5:0.95\n",
        "# - ê°„ë‹¨ Precision/Recall (IoU=0.5, greedy 1:1 ë§¤ì¹­)\n",
        "# - Latency/FPS (ìƒ˜í”Œ 64ì¥)\n",
        "# - ëª¨ë¸ í¬ê¸°(ë°”ì´íŠ¸) / íŒŒë¼ë¯¸í„° ìˆ˜\n",
        "# - í•™ìŠµì‹œê°„(ê¸°ë³¸ 0, ì˜µì…˜: ì§§ê²Œ í•™ìŠµí•˜ê³  ì¸¡ì • ê°€ëŠ¥)\n",
        "# ============================================================\n",
        "\n",
        "import os, time, json, math, random, warnings, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning,\n",
        "                        message=r\".*torch\\.cuda\\.amp\\.autocast.*\")\n",
        "\n",
        "# -----------------------------\n",
        "# 0) ì„¤ì •\n",
        "# -----------------------------\n",
        "ROOT = Path(\"/content\")\n",
        "COCO_DIR = ROOT/\"coco\"\n",
        "ANN_JSON = COCO_DIR/\"annotations\"/\"instances_val2017.json\"\n",
        "VAL_DIR  = COCO_DIR/\"val2017\"          # val ì´ë¯¸ì§€ í´ë”\n",
        "OUTPUT   = ROOT/\"yolov5s_eval_out\"     # ë¡œê·¸ ì €ì¥ ê²½ë¡œ\n",
        "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"yolov5s\"\n",
        "IMG_SIZE = 640\n",
        "CONF_THR = 0.25\n",
        "IOU_THR  = 0.50\n",
        "LAT_SAMPLES = 64\n",
        "DO_TRAIN = False  # Trueë¡œ ë†“ìœ¼ë©´ ì•„ì£¼ ì§§ê²Œ í•™ìŠµì„ ëŒë¦¬ê³  í•™ìŠµì‹œê°„ ì¸¡ì •(ê¶Œì¥X: ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤)\n",
        "\n",
        "MAP_CSV    = OUTPUT/\"map.csv\"\n",
        "PR_CSV     = OUTPUT/\"pr.csv\"\n",
        "LAT_TXT    = OUTPUT/\"latency.json\"\n",
        "SIZE_TXT   = OUTPUT/\"size.json\"\n",
        "TRAIN_TIME = OUTPUT/\"train_time.txt\"\n",
        "\n",
        "# -----------------------------\n",
        "# 1) í•„ìˆ˜ ì„¤ì¹˜ & ë°ì´í„° ì¤€ë¹„\n",
        "# -----------------------------\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install pycocotools opencv-python torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "!git -C /content clone -q https://github.com/ultralytics/yolov5.git || true\n",
        "!pip -q install -r /content/yolov5/requirements.txt\n",
        "\n",
        "# COCO val2017 ë‹¤ìš´ë¡œë“œ(ì´ë¯¸ ë°›ì•˜ë‹¤ë©´ ê±´ë„ˆëœë‹ˆë‹¤)\n",
        "if not ANN_JSON.exists():\n",
        "    COCO_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    # ì–´ë…¸í…Œì´ì…˜\n",
        "    !mkdir -p /content/coco/annotations\n",
        "    !wget -qO /content/coco/annotations_trainval2017.zip http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "    !unzip -q /content/coco/annotations_trainval2017.zip -d /content/coco\n",
        "    # val ì´ë¯¸ì§€\n",
        "    !wget -qO /content/coco/val2017.zip http://images.cocodataset.org/zips/val2017.zip\n",
        "    !unzip -q /content/coco/val2017.zip -d /content/coco\n",
        "\n",
        "print(\"COCO paths ready:\", ANN_JSON.exists(), VAL_DIR.exists())\n",
        "\n",
        "# -----------------------------\n",
        "# 2) YOLOv5s ë¡œë“œ\n",
        "# -----------------------------\n",
        "import torch\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "yolo = torch.hub.load('ultralytics/yolov5', MODEL_NAME, pretrained=True, source='github', force_reload=True).to(DEVICE)\n",
        "yolo.conf = CONF_THR\n",
        "yolo.iou  = IOU_THR\n",
        "yolo.max_det = 300\n",
        "NAMES = yolo.names  # {0:'person', 1:'bicycle', ...}\n",
        "\n",
        "# -----------------------------\n",
        "# 3) COCO API & ì¹´í…Œê³ ë¦¬ ë§¤í•‘\n",
        "# -----------------------------\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "cocoGt = COCO(str(ANN_JSON))\n",
        "\n",
        "# COCO: name -> category_id (COCOëŠ” 1,2,3... ë¹„ì—°ì† id)\n",
        "cats = cocoGt.loadCats(cocoGt.getCatIds())\n",
        "NAME2CATID = {c['name']: c['id'] for c in cats}\n",
        "IDX2CATID  = {i: NAME2CATID.get(name, None) for i, name in NAMES.items()}\n",
        "\n",
        "# -----------------------------\n",
        "# 4) (ì˜µì…˜) ì•„ì£¼ ì§§ê²Œ í•™ìŠµ ëŒë ¤ì„œ í•™ìŠµì‹œê°„ ì¸¡ì •\n",
        "# -----------------------------\n",
        "train_time_sec = 0.0\n",
        "if DO_TRAIN:\n",
        "    import subprocess, shlex\n",
        "    # ultralytics/yolov5ì˜ train.pyë¥¼ ì´ìš©í•´ COCOì˜ 80í´ë˜ìŠ¤ë¡œ ì•„ì£¼ ì§§ê²Œ í•™ìŠµ (ë°ëª¨ìš©)\n",
        "    # â€» ì‹¤ì œ COCO í•™ìŠµì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” epochs=1~3 ì •ë„ë¡œ ë°ëª¨ë§Œ ê¶Œì¥\n",
        "    t0 = time.time()\n",
        "    cmd = f\"python /content/yolov5/train.py --img {IMG_SIZE} --batch 16 --epochs 1 --data coco.yaml --weights {MODEL_NAME}.pt --device 0 --project {OUTPUT} --name train_demo\"\n",
        "    print(\"Running:\", cmd)\n",
        "    p = subprocess.run(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    print(p.stdout)\n",
        "    train_time_sec = time.time() - t0\n",
        "\n",
        "# -----------------------------\n",
        "# 5) ì˜ˆì¸¡ ìˆ˜ì§‘ â†’ COCO mAP í‰ê°€\n",
        "# -----------------------------\n",
        "img_ids = cocoGt.getImgIds()\n",
        "imgs = cocoGt.loadImgs(img_ids)\n",
        "\n",
        "def run_detector(image_bgr):\n",
        "    img_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "    with torch.no_grad():\n",
        "        res = yolo(img_rgb, size=IMG_SIZE)\n",
        "    dets=[]\n",
        "    if hasattr(res, \"xyxy\") and len(res.xyxy):\n",
        "        arr = res.xyxy[0].detach().cpu().numpy()  # x1,y1,x2,y2,conf,cls\n",
        "        for x1, y1, x2, y2, score, cls in arr:\n",
        "            cls = int(cls)\n",
        "            cat_id = IDX2CATID.get(cls)  # COCO category_idë¡œ ë³€í™˜\n",
        "            if cat_id is None:  # í˜¹ì‹œ ì´ë¦„ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ\n",
        "                continue\n",
        "            dets.append({\n",
        "                \"bbox\": [int(x1), int(y1), int(x2), int(y2)],\n",
        "                \"score\": float(score),\n",
        "                \"category_id\": int(cat_id)\n",
        "            })\n",
        "    return dets\n",
        "\n",
        "preds = []\n",
        "val_image_paths = []\n",
        "t_eval0 = time.time()\n",
        "for im in imgs:\n",
        "    file_name = im[\"file_name\"]  # e.g., 000000397133.jpg\n",
        "    img_path = str(VAL_DIR / file_name)\n",
        "    val_image_paths.append(img_path)\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        continue\n",
        "    dets = run_detector(img)\n",
        "    for d in dets:\n",
        "        x1,y1,x2,y2 = d[\"bbox\"]\n",
        "        w = max(0, x2 - x1); h = max(0, y2 - y1)\n",
        "        preds.append({\n",
        "            \"image_id\": int(im[\"id\"]),\n",
        "            \"category_id\": int(d[\"category_id\"]),\n",
        "            \"bbox\": [float(x1), float(y1), float(w), float(h)],  # COCO format [x,y,w,h]\n",
        "            \"score\": float(d[\"score\"])\n",
        "        })\n",
        "eval_time_sec = time.time() - t_eval0\n",
        "\n",
        "if len(preds)==0:\n",
        "    map50 = 0.0; map5095 = 0.0\n",
        "    print(\"No predictions collected.\")\n",
        "else:\n",
        "    cocoDt = cocoGt.loadRes(preds)\n",
        "    cocoEval = COCOeval(cocoGt, cocoDt, iouType='bbox')\n",
        "    cocoEval.evaluate(); cocoEval.accumulate(); cocoEval.summarize()\n",
        "    map5095 = float(cocoEval.stats[0])  # mAP@0.5:0.95\n",
        "    map50   = float(cocoEval.stats[1])  # mAP@0.5\n",
        "\n",
        "# -----------------------------\n",
        "# 6) ê°„ë‹¨ Precision / Recall (IoU=0.5)\n",
        "# -----------------------------\n",
        "def iou_xyxy(a, b):\n",
        "    ax1,ay1,ax2,ay2 = a; bx1,by1,bx2,by2 = b\n",
        "    ix1,iy1 = max(ax1,bx1), max(ay1,by1)\n",
        "    ix2,iy2 = min(ax2,bx2), min(ay2,by2)\n",
        "    iw,ih = max(0, ix2-ix1), max(0, iy2-iy1)\n",
        "    inter = iw*ih\n",
        "    ua = max(0, ax2-ax1)*max(0, ay2-ay1)\n",
        "    ub = max(0, bx2-bx1)*max(0, by2-by1)\n",
        "    union = ua + ub - inter + 1e-9\n",
        "    return inter/union\n",
        "\n",
        "# GT ì¸ë±ìŠ¤: image_id -> [boxes]\n",
        "gt_by_img = {}\n",
        "for ann in cocoGt.dataset[\"annotations\"]:\n",
        "    x,y,w,h = ann[\"bbox\"]\n",
        "    gt_by_img.setdefault(ann[\"image_id\"], []).append([x,y,x+w,y+h])\n",
        "\n",
        "# Pred ì¸ë±ìŠ¤: image_id -> [(box, score)]\n",
        "pred_by_img={}\n",
        "for pr in preds:\n",
        "    x,y,w,h = pr[\"bbox\"]\n",
        "    pred_by_img.setdefault(pr[\"image_id\"], []).append(([x,y,x+w,y+h], pr[\"score\"]))\n",
        "\n",
        "TP=FP=FN=0\n",
        "for img_id, gts in gt_by_img.items():\n",
        "    prs = pred_by_img.get(img_id, [])\n",
        "    matched=set()\n",
        "    prs = sorted(prs, key=lambda x: -x[1])\n",
        "    for p_box, _ in prs:\n",
        "        ok=False\n",
        "        for j, g_box in enumerate(gts):\n",
        "            if j in matched:\n",
        "                continue\n",
        "            if iou_xyxy(p_box, g_box) >= 0.5:\n",
        "                TP+=1; matched.add(j); ok=True; break\n",
        "        if not ok:\n",
        "            FP+=1\n",
        "    FN += (len(gts) - len(matched))\n",
        "\n",
        "precision = TP / (TP+FP+1e-9)\n",
        "recall    = TP / (TP+FN+1e-9)\n",
        "\n",
        "# -----------------------------\n",
        "# 7) Latency/FPS ì¸¡ì • (ìƒ˜í”Œ 64ì¥)\n",
        "# -----------------------------\n",
        "def measure_latency(paths, max_samples=64):\n",
        "    paths = paths[:max_samples]\n",
        "    if not paths: return math.nan, math.nan\n",
        "    # warm-up\n",
        "    dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
        "    for _ in range(5): _ = run_detector(dummy)\n",
        "    if DEVICE == 'cuda': torch.cuda.synchronize()\n",
        "\n",
        "    times=[]\n",
        "    for p in paths:\n",
        "        img = cv2.imread(p)\n",
        "        if img is None: continue\n",
        "        t0=time.time()\n",
        "        _ = run_detector(img)\n",
        "        if DEVICE == 'cuda': torch.cuda.synchronize()\n",
        "        times.append((time.time()-t0)*1000.0)\n",
        "    if not times: return math.nan, math.nan\n",
        "    avg_ms = float(np.mean(times))\n",
        "    fps = 1000.0/avg_ms if avg_ms>0 else math.nan\n",
        "    return avg_ms, fps\n",
        "\n",
        "random.shuffle(val_image_paths)\n",
        "avg_ms, fps = measure_latency(val_image_paths, LAT_SAMPLES)\n",
        "\n",
        "# -----------------------------\n",
        "# 8) ëª¨ë¸ í¬ê¸° / íŒŒë¼ë¯¸í„° ìˆ˜\n",
        "# -----------------------------\n",
        "TMP_W = OUTPUT/\"yolov5s_tmp_weights.pt\"\n",
        "file_bytes = -1\n",
        "try:\n",
        "    torch.save(yolo.model.state_dict(), TMP_W)\n",
        "    file_bytes = int(TMP_W.stat().st_size)\n",
        "except Exception:\n",
        "    pass\n",
        "num_params = int(sum(p.numel() for p in yolo.model.parameters()))\n",
        "\n",
        "# -----------------------------\n",
        "# 9) ë¡œê·¸ ì €ì¥\n",
        "# -----------------------------\n",
        "pd.DataFrame([{\"split\":\"val2017\",\"map50\":map50,\"map50_95\":map5095}]).to_csv(MAP_CSV, index=False)\n",
        "pd.DataFrame([{\"split\":\"val2017\",\"precision\":precision,\"recall\":recall}]).to_csv(PR_CSV, index=False)\n",
        "with open(LAT_TXT, \"w\") as f:\n",
        "    json.dump({\"avg_ms_per_image\":avg_ms, \"fps\":fps, \"eval_time_sec\":eval_time_sec}, f)\n",
        "with open(SIZE_TXT, \"w\") as f:\n",
        "    json.dump({\"file_bytes\":file_bytes, \"num_params\":num_params}, f)\n",
        "with open(TRAIN_TIME, \"w\") as f:\n",
        "    f.write(f\"{train_time_sec:.6f}\")\n",
        "\n",
        "print(\"\\n=== SUMMARY ===\")\n",
        "print(\"mAP@0.5:0.95:\", map5095)\n",
        "print(\"mAP@0.5    :\", map50)\n",
        "print(\"Precision  :\", precision)\n",
        "print(\"Recall     :\", recall)\n",
        "print(\"Latency(ms):\", avg_ms, \"| FPS:\", fps)\n",
        "print(\"Params     :\", num_params, \"| Weights file size(bytes):\", file_bytes)\n",
        "print(\"Train time :\", train_time_sec, \"sec\")\n",
        "print(\"Logs saved :\", str(OUTPUT))\n"
      ]
    }
  ]
}